{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this project, we will create a simple classifier that determines: CHIHUAHUA… or MUFFIN!\n",
    "\n",
    "First, let's see what we will cover in this tutorial!\n",
    "\n",
    "* Review of Machine Learning pipeline, Deep Learning and neurual networks\n",
    "* Install packages and set up the environment\n",
    "* Start Deep Learning \n",
    "    * Load the dataset\n",
    "    * Define train parameters\n",
    "    * Create train loop (building our model)\n",
    "    * Save the model\n",
    "* Test the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Machine Learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In general, Machine Learning means that we let the computer \"learn\" from some existing dataset，or extract the \"pattern\" into a model. Later the computer could use the model to predict new data that the it has never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"resources/dl_pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Machine Learning vs Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In short, Deep Learning is as subset of Machine Learning, but can be a really powerful tool to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br>\n",
    "<center><img src=\"resources/ml_vs_dl.png\" width =\"600\"></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[Image source](https://www.onepetro.org/conference-paper/URTEC-2901881-MS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "An example of deep neural networks that might not be \"deep\" enough (only two hidden layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br>\n",
    "<center><img src=\"resources/neural_network_layers.jpg\" width =\"600\" align=\"center\"/></center>\n",
    "\n",
    "[Image source]( http://cs231n.github.io/neural-networks-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this project, we are going to use an exisiting model (ResNet) that is trained by someone else and build our own model above it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"resources/folders.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# == Part 0a: Installation and Setup =="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Install Python\n",
    "\n",
    "https://www.python.org/downloads/release/python-373/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Install prerequisite dependencies\n",
    "```\n",
    "pip install numpy jupyter matplotlib pillow tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Install PyTorch! https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"Pytorch_logo.png\" width=\"300\">\n",
    "<img src=\"install_pytorch_mac_cpu.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Open this interactive Notebook on your computer!\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/sjsumlclub/[OUR_WORKSHOP].git\n",
    "cd [OUR_WORKSHOP]\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# == Part 0b: Download Data ==\n",
    "https://www.kaggle.com/pmigdal/alien-vs-predator-images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# == Part 1: Deep Learning ==\n",
    "\n",
    "Credit for the original code base goes to https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/! We've modified it to fit this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Generic Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np               # linear algebra library\n",
    "import matplotlib.pyplot as plt  # graphing library\n",
    "from PIL import Image            # (pillow): image manipulation and loading\n",
    "%matplotlib inline               # special Jupyter notebook command to show graphs in this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Deep learning imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import torch                                            # PyTorch deep learning framework\n",
    "from torchvision import datasets, models, transforms    # extension to PyTorch for dataset management\n",
    "import torch.nn as nn                                   # neural networks module of PyTorch, to let us define neural network layers\n",
    "from torch.nn import functional as F                    # special functions\n",
    "import torch.optim as optim                             # optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### @AJ_Comment TODO: what if we take out normalization and data augmentation at first, so that they can try adding it themselves later?\n",
    "#### Distribution of RGB channels on ImageNet; we normalize the channels for more consistent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# a dictionary of data transforms for our train and validation set\n",
    "train_transforms = transforms.Compose([\n",
    "    # resize to resnet input size\n",
    "    transforms.Resize((224,224)),\n",
    "    # do some data augmentation\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transform image to PyTorch tensor object\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "image_datasets = {\n",
    "    'train':\n",
    "        datasets.ImageFolder('data/train',train_transforms),\n",
    "    'validation':\n",
    "        datasets.ImageFolder('data/validation', validation_transforms)}\n",
    " \n",
    "dataloaders = {\n",
    "    'train':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['train'],\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            num_workers=4),\n",
    "    'validation':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['validation'],\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define Train Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Choose GPU (cuda) or CPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # cuda:0 means the first cuda device found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Choose our neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model = models.resnet18(pretrained=True).to(device)                      # load our simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### We freeze the internal layers so they don't train them on our new dataset. Instead, we add a couple layers at the end that will do the learning for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Freeze the internal layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "last_layer_size = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Add two layers at the end\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(layer_layer_size, 128),           # layer 1\n",
    "    nn.ReLU(inplace=True),          # activate layer 1\n",
    "    nn.Linear(128, 2)).to(device)   # layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Define the loss function and optimizer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create our train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Define the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from tqdm import tnrange, tqdm_notebook # import sexy progress bars\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    # train for x epochs. an epoch is a full iteration through our dataset\n",
    "    for epoch in tnrange(num_epochs, desc=\"Total progress\", unit=\"epoch\"):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # first train one step and update weights; then after that train step, check our validation loss\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase], desc=phase, unit=\"batch\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "            print(f'{phase} loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### run the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model_trained = train_model(model, criterion, optimizer, num_epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the model to our computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model_file = os.path.join(MODEL_DIR, \"weights.pth\")\n",
    "torch.save(model_trained.state_dict(),model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model = models.resnet18(pretrained=False).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(last_layer_size, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    "model.load_state_dict(torch.load(model_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visually test model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Choose some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "validation_img_paths = [\"data/validation/alien/11.jpg\",\n",
    "                        \"data/validation/alien/22.jpg\",\n",
    "                        \"data/validation/predator/33.jpg\"]\n",
    "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Calculate the prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "validation_batch = torch.stack( [validation_transforms(img).to(device) for img in img_list] )\n",
    " \n",
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n",
    "                                                          100*pred_probs[i,1]))\n",
    "    ax.imshow(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}