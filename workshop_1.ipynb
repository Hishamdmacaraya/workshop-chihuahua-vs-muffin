{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this project, we will create a simple classifier that determines: CHIHUAHUA… or MUFFIN!\n",
    "\n",
    "First, let's see what we will cover in this tutorial!\n",
    "\n",
    "* Review of Machine Learning pipeline, Deep Learning and neurual networks\n",
    "* Install packages and set up the environment\n",
    "* Start Deep Learning \n",
    "    * Load the dataset\n",
    "    * Define train parameters\n",
    "    * Create train loop (building our model)\n",
    "    * Save the model\n",
    "* Test the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Machine Learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In general, Machine Learning means that we let the computer \"learn\" from some existing dataset，or extract the \"pattern\" into a model. Later the computer could use the model to predict new data that the it has never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"resources/dl_pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Machine Learning vs Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In short, Deep Learning is as subset of Machine Learning, but can be a really powerful tool to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br>\n",
    "<center><img src=\"resources/ml_vs_dl.png\" width =\"600\"></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[Image source](https://www.onepetro.org/conference-paper/URTEC-2901881-MS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "An example of deep neural networks that might not be \"deep\" enough (only two hidden layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br>\n",
    "<center><img src=\"resources/neural_network_layers.jpg\" width =\"600\" align=\"center\"/></center>\n",
    "\n",
    "[Image source]( http://cs231n.github.io/neural-networks-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"resources/training_testing_pipeline.png\" width =\"1000\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[Image source]( https://towardsdatascience.com/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this project, we are going to use an exisiting model (ResNet) that is trained by someone else and build our own model above it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"resources/folders.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Download Data\n",
    "https://drive.google.com/open?id=1MWIHR2zC9ty2B3O2aIEfMHJ3HNbeBkVV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "Credit for the original code base goes to https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/! We've modified it to fit this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Generic Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np               # linear algebra library\n",
    "import math\n",
    "import matplotlib.pyplot as plt  # graphing library\n",
    "from PIL import Image            # (pillow): image manipulation and loading\n",
    "%matplotlib inline               # special Jupyter notebook command to show graphs in this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Deep learning imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import torch                                            # PyTorch deep learning framework\n",
    "from torchvision import datasets, models, transforms    # extension to PyTorch for dataset management\n",
    "import torch.nn as nn                                   # neural networks module of PyTorch, to let us define neural network layers\n",
    "from torch.nn import functional as F                    # special functions\n",
    "import torch.optim as optim                             # optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Distribution of RGB channels on ImageNet; we normalize the channels for more consistent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# a dictionary of data transforms for our train and validation set\n",
    "train_transforms = transforms.Compose([\n",
    "    # resize to resnet input size\n",
    "    transforms.Resize((224,224)),\n",
    "    # transform image to PyTorch tensor object\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For more information about transforms, check out the link here: https://pytorch.org/docs/stable/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "image_datasets = {\n",
    "    'train':\n",
    "        datasets.ImageFolder('data/train',train_transforms),\n",
    "    'validation':\n",
    "        datasets.ImageFolder('data/validation', validation_transforms)}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['train'],\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            num_workers=4),\n",
    "    'validation':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['validation'],\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define Train Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Choose GPU (cuda) or CPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # cuda:0 means the first cuda device found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Choose neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model = models.resnet18(pretrained=True).to(device)                      # load our simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Freeze internal layers, train on 2 added layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Freeze the internal layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "last_layer_size = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Add two layers at the end\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(last_layer_size, 128),           # layer 1\n",
    "    nn.ReLU(inplace=True),          # activate layer 1\n",
    "    nn.Linear(128, 2)).to(device)   # layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Define the loss function and optimizer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create our train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Define the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from tqdm import tnrange, tqdm_notebook # import sexy progress bars\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    # train for x epochs. an epoch is a full iteration through our dataset\n",
    "    for epoch in tnrange(num_epochs, desc=\"Total progress\", unit=\"epoch\"):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # first train one step and update weights; then after that train step, check our validation loss\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase], desc=phase, unit=\"batch\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "            print(f'{phase} loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### run the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model_trained = train_model(model, criterion, optimizer, num_epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save the model to our computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model_file = os.path.join(MODEL_DIR, \"weights.pth\")\n",
    "torch.save(model_trained.state_dict(),model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model = models.resnet18(pretrained=False).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(last_layer_size, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    "model.load_state_dict(torch.load(model_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visually test model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Choose some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "validation_img_paths = [\"data/validation/chihuahua/cashew13.jpg\",\n",
    "                        \"data/validation/chihuahua/cashew4.jpg\",\n",
    "                        \"data/validation/chihuahua/cashew6.jpg\",\n",
    "                        \"data/validation/chihuahua/cashew7.jpg\",\n",
    "                        \"data/validation/chihuahua/21.jpg\",\n",
    "                        \"data/validation/chihuahua/27.jpg\",\n",
    "                        \"data/validation/chihuahua/34.jpg\",\n",
    "                        \"data/validation/chihuahua/35.jpg\",\n",
    "                        \"data/validation/chihuahua/39.jpg\",\n",
    "                        \"data/validation/chihuahua/43.jpg\",\n",
    "                        \"data/validation/chihuahua/44.jpg\",\n",
    "                        \"data/validation/chihuahua/46.jpg\",\n",
    "                        \"data/validation/chihuahua/48.jpg\",\n",
    "                        \"data/validation/chihuahua/51.jpg\",\n",
    "                        \"data/validation/chihuahua/52.jpg\",\n",
    "                        \"data/validation/chihuahua/67.jpg\",\n",
    "                        \"data/validation/chihuahua/8.jpg\",\n",
    "                        \"data/validation/muffin/101.jpg\",\n",
    "                        \"data/validation/muffin/105.jpg\",\n",
    "                        \"data/validation/muffin/108.jpg\",\n",
    "                        \"data/validation/muffin/112.jpg\",\n",
    "                        \"data/validation/muffin/122.jpg\",\n",
    "                        \"data/validation/muffin/133.jpg\",\n",
    "                        \"data/validation/muffin/74.jpg\",\n",
    "                        \"data/validation/muffin/75.jpg\",\n",
    "                        \"data/validation/muffin/89.jpg\",\n",
    "                        \"data/validation/muffin/90.jpg\",\n",
    "                        \"data/validation/muffin/92.jpg\",\n",
    "                        \"data/validation/muffin/93.jpg\",\n",
    "                        \"data/validation/muffin/95.jpg\"]\n",
    "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Calculate the prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "validation_batch = torch.stack( [validation_transforms(img).to(device) for img in img_list] )\n",
    " \n",
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig, axs = plt.subplots(6, 5, figsize=(20, 20))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[math.floor(i/5)][i % 5]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}% Chihuahua, {:.0f}% Muffin\".format(100*pred_probs[i,0], 100*pred_probs[i,1]))\n",
    "    ax.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}